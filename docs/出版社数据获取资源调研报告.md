# 出版社数据获取资源调研报告

## 文档信息

| 项目 | 内容 |
|------|------|
| 文档版本 | v1.0 |
| 创建日期 | 2026-02-26 |
| 调研目的 | 了解各大出版社官方API情况及新书目录页面 |

---

## 一、调研结论摘要

### 1.1 官方API情况

| 出版社 | 官方API | 说明 |
|--------|:-------:|------|
| Penguin Random House | ❌ 无 | 无公开开发者API |
| Simon & Schuster | ❌ 无 | 无公开开发者API |
| HarperCollins | ❌ 无 | 无公开开发者API |
| Macmillan | ❌ 无 | 无公开开发者API |
| Hachette | ❌ 无 | 无公开开发者API |

> **结论**：五大出版社均未提供公开的图书数据API，需要通过网页爬虫获取新书信息。

### 1.2 替代数据源

| 数据源 | 类型 | 免费 | 覆盖范围 | 推荐度 |
|--------|:----:|:----:|----------|:------:|
| Google Books API | 官方API | ✅ | 全球图书 | ⭐⭐⭐⭐⭐ |
| Open Library API | 开放API | ✅ | 全球图书 | ⭐⭐⭐⭐⭐ |
| NYT Books API | 官方API | ✅ | 畅销书榜 | ⭐⭐⭐⭐ |
| ISBN查询API | 第三方 | ❌ | 中文图书 | ⭐⭐⭐ |

---

## 二、五大出版社详细资源

### 2.1 Penguin Random House（企鹅兰登）

| 项目 | 内容 |
|------|------|
| **中文名称** | 企鹅兰登书屋 |
| **总部** | 美国纽约 |
| **市场份额** | 全球第一（约25%） |
| **旗下品牌** | Knopf, Viking, Crown, Ballantine, Del Rey 等 |

#### 官方网站

| 页面类型 | URL |
|----------|-----|
| 主页 | https://www.penguinrandomhouse.com/ |
| **新书发布** | https://www.penguinrandomhouse.com/books/new-releases/ |
| 即将出版 | https://www.penguinrandomhouse.com/books/coming-soon/ |
| 畅销书 | https://www.penguinrandomhouse.com/books/best-sellers/ |
| 按类别新书 | https://www.penguinrandomhouse.com/books/new-releases-fiction/ |
| 儿童新书 | https://www.penguinrandomhouse.com/books/new-releases-childrens/ |

#### 数据获取方式

```
方式：网页爬虫
难度：⭐⭐ 中等
特点：
- 网站结构清晰，使用 .carousel .item 选择器
- 支持按类别筛选
- 包含书名、作者、封面、ISBN等信息
```

---

### 2.2 Simon & Schuster（西蒙与舒斯特）

| 项目 | 内容 |
|------|------|
| **中文名称** | 西蒙与舒斯特 |
| **总部** | 美国纽约 |
| **母公司** | KKR（私募股权） |
| **旗下品牌** | Scribner, Atria, Gallery, Touchstone 等 |

#### 官方网站

| 页面类型 | URL |
|----------|-----|
| 主页 | https://www.simonandschuster.com/ |
| **新书发布** | https://www.simonandschuster.com/books/new-releases |
| 即将出版 | https://www.simonandschuster.com/books/coming-soon |
| 畅销书 | https://www.simonandschuster.com/books/bestsellers |
| 儿童图书 | https://www.simonandschuster.com/kids |

#### 数据获取方式

```
方式：网页爬虫
难度：⭐⭐⭐ 较难
特点：
- 网站使用JavaScript渲染
- 需要等待页面加载完成
- 包含书名、作者、ISBN、价格等信息
```

---

### 2.3 HarperCollins（哈珀柯林斯）

| 项目 | 内容 |
|------|------|
| **中文名称** | 哈珀柯林斯 |
| **总部** | 美国纽约 |
| **母公司** | 新闻集团（News Corp） |
| **旗下品牌** | William Morrow, Avon, Harper, Ecco 等 |

#### 官方网站

| 页面类型 | URL |
|----------|-----|
| 主页 | https://www.harpercollins.com/ |
| **新书发布** | https://www.harpercollins.com/pages/new-releases |
| 即将出版 | https://www.harpercollins.com/pages/coming-soon |
| 畅销书 | https://www.harpercollins.com/pages/bestsellers |
| 英国站 | https://www.harpercollins.co.uk/ |

#### 数据获取方式

```
方式：网页爬虫
难度：⭐⭐⭐ 较难
特点：
- 网站结构相对复杂
- 需要处理分页
- 包含书名、作者、封面、简介等信息
```

---

### 2.4 Macmillan（麦克米伦）

| 项目 | 内容 |
|------|------|
| **中文名称** | 麦克米伦出版社 |
| **总部** | 英国伦敦 / 美国纽约 |
| **母公司** | Holtzbrinck Publishing Group |
| **旗下品牌** | Farrar, Henry Holt, St. Martin's, Tor 等 |

#### 官方网站

| 页面类型 | URL |
|----------|-----|
| 主页 | https://us.macmillan.com/ |
| **新书发布** | https://us.macmillan.com/books/new-releases |
| 即将出版 | https://us.macmillan.com/books/coming-soon |
| 畅销书 | https://us.macmillan.com/books/bestsellers |
| 儿童图书 | https://us.macmillan.com/kids |

#### 数据获取方式

```
方式：网页爬虫
难度：⭐⭐⭐ 较难
特点：
- 网站设计简洁
- 数据结构化程度较高
- 包含书名、作者、ISBN、价格等信息
```

---

### 2.5 Hachette Book Group（阿歇特）

| 项目 | 内容 |
|------|------|
| **中文名称** | 阿歇特图书集团 |
| **总部** | 美国纽约 |
| **母公司** | Hachette Livre（法国） |
| **旗下品牌** | Little, Brown, Grand Central, Orbit, Basic Books 等 |

#### 官方网站

| 页面类型 | URL |
|----------|-----|
| 主页 | https://www.hachettebookgroup.com/ |
| **新书发布** | https://www.hachettebookgroup.com/books/new-releases/ |
| 即将出版 | https://www.hachettebookgroup.com/books/coming-soon/ |
| 畅销书 | https://www.hachettebookgroup.com/books/bestsellers/ |
| 英国站 | https://www.hachette.co.uk/ |

#### 数据获取方式

```
方式：网页爬虫
难度：⭐⭐⭐ 较难
特点：
- 网站结构清晰
- 支持按品牌筛选
- 包含书名、作者、ISBN、简介等信息
```

---

## 三、第三方图书数据API

### 3.1 Google Books API（推荐）

| 项目 | 内容 |
|------|------|
| **官方文档** | https://developers.google.com/books |
| **费用** | 免费 |
| **限制** | 1000次/天（无需API Key） |
| **覆盖范围** | 全球图书 |

#### API使用示例

```python
# 按ISBN查询
import requests

isbn = "9780345807007"
url = f"https://www.googleapis.com/books/v1/volumes?q=isbn:{isbn}"
response = requests.get(url)
data = response.json()

if data.get('items'):
    book = data['items'][0]['volumeInfo']
    print(f"书名: {book.get('title')}")
    print(f"作者: {book.get('authors', [])}")
    print(f"出版社: {book.get('publisher')}")
    print(f"出版日期: {book.get('publishedDate')}")
```

#### 支持的查询方式

| 查询类型 | URL格式 |
|----------|---------|
| ISBN查询 | `?q=isbn:9780345807007` |
| 书名查询 | `?q=intitle:Harry Potter` |
| 作者查询 | `?q=inauthor:Stephen King` |
| 出版社查询 | `?q=inpublisher:Penguin` |
| 关键词查询 | `?q=python programming` |

---

### 3.2 Open Library API（推荐）

| 项目 | 内容 |
|------|------|
| **官方网站** | https://openlibrary.org/ |
| **API文档** | https://openlibrary.org/developers/api |
| **费用** | 免费 |
| **限制** | 无严格限制 |
| **覆盖范围** | 全球图书 |

#### API使用示例

```python
import requests

# 按ISBN查询
isbn = "9780345807007"
url = f"https://openlibrary.org/api/books?bibkeys=ISBN:{isbn}&format=json&jscmd=data"
response = requests.get(url)
data = response.json()

book_key = f"ISBN:{isbn}"
if book_key in data:
    book = data[book_key]
    print(f"书名: {book.get('title')}")
    print(f"作者: {book.get('authors', [])}")
    print(f"封面: {book.get('cover', {}).get('medium')}")
```

---

### 3.3 NYT Books API

| 项目 | 内容 |
|------|------|
| **官方文档** | https://developer.nytimes.com/docs/books-product/1/overview |
| **费用** | 免费 |
| **限制** | 500次/天 |
| **覆盖范围** | 纽约时报畅销书榜 |

#### API使用示例

```python
import requests

api_key = "YOUR_API_KEY"
url = f"https://api.nytimes.com/svc/books/v3/lists/current/hardcover-fiction.json?api-key={api_key}"
response = requests.get(url)
data = response.json()

for book in data['results']['books']:
    print(f"排名: {book['rank']}")
    print(f"书名: {book['title']}")
    print(f"作者: {book['author']}")
    print(f"ISBN: {book['primary_isbn13']}")
```

---

## 四、其他知名出版社资源

### 4.1 英国出版社

| 出版社 | 主页 | 新书页面 |
|--------|------|----------|
| Bloomsbury | https://www.bloomsbury.com/ | https://www.bloomsbury.com/uk/new-books/ |
| Oxford University Press | https://global.oup.com/ | https://global.oup.com/academic/new/ |
| Cambridge University Press | https://www.cambridge.org/ | https://www.cambridge.org/new-books |
| Usborne | https://usborne.com/ | https://usborne.com/gb/books/new-this-month |

### 4.2 美国出版社

| 出版社 | 主页 | 新书页面 |
|--------|------|----------|
| Scholastic | https://www.scholastic.com/ | https://www.scholastic.com/home/new-releases/ |
| DK | https://www.dk.com/ | https://www.dk.com/us/new-books |
| Chronicle Books | https://www.chroniclebooks.com/ | https://www.chroniclebooks.com/new-releases |
| National Geographic | https://www.nationalgeographic.com/books/ | https://www.nationalgeographic.com/books/new-releases/ |

### 4.3 专业/学术出版社

| 出版社 | 主页 | 新书页面 |
|--------|------|----------|
| Springer Nature | https://www.springernature.com/ | https://www.springernature.com/gp/new-releases |
| Wiley | https://www.wiley.com/ | https://www.wiley.com/en-us/new-releases |
| Elsevier | https://www.elsevier.com/ | https://www.elsevier.com/books/new-books |
| MIT Press | https://mitpress.mit.edu/ | https://mitpress.mit.edu/new-books |

### 4.4 儿童图书出版社

| 出版社 | 主页 | 新书页面 |
|--------|------|----------|
| Candlewick Press | https://www.candlewick.com/ | https://www.candlewick.com/new-books/ |
| Nosy Crow | https://nosycrow.com/ | https://nosycrow.com/new-books/ |
| Egmont | https://www.egmont.co.uk/ | https://www.egmont.co.uk/new-books/ |
| Carlton Kids | https://www.carltonbooks.co.uk/ | https://www.carltonbooks.co.uk/kids-books |

---

## 五、爬虫技术建议

### 5.1 推荐技术栈

| 技术 | 用途 | 说明 |
|------|------|------|
| **requests** | HTTP请求 | 简单易用，支持会话管理 |
| **BeautifulSoup** | HTML解析 | 适合静态页面 |
| **Playwright** | 浏览器自动化 | 适合JavaScript渲染页面 |
| **lxml** | XML/HTML解析 | 性能优秀 |

### 5.2 爬虫注意事项

| 注意事项 | 说明 |
|----------|------|
| **遵守 robots.txt** | 检查网站的爬虫协议 |
| **设置请求间隔** | 避免对服务器造成压力 |
| **使用 User-Agent** | 模拟正常浏览器访问 |
| **处理反爬虫** | 使用代理、随机延迟等 |
| **数据缓存** | 避免重复请求 |

### 5.3 爬虫代码示例

```python
import requests
from bs4 import BeautifulSoup
import time
import random

class BaseCrawler:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def fetch(self, url: str) -> BeautifulSoup:
        """获取页面并解析"""
        response = self.session.get(url, timeout=15)
        response.raise_for_status()
        
        # 随机延迟，避免被封
        time.sleep(random.uniform(1, 3))
        
        return BeautifulSoup(response.text, 'lxml')
    
    def check_robots_txt(self, base_url: str) -> bool:
        """检查robots.txt"""
        try:
            robots_url = f"{base_url}/robots.txt"
            response = self.session.get(robots_url, timeout=10)
            # 解析robots.txt规则
            return True
        except:
            return True
```

---

## 六、数据获取策略建议

### 6.1 推荐方案

```
┌─────────────────────────────────────────────────────────────────┐
│                     图书数据获取策略                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  1. 主数据源：出版社网站爬虫                                       │
│     ├── 获取最新出版信息                                          │
│     ├── 包含出版社独家内容                                        │
│     └── 需要定期维护                                              │
│                                                                 │
│  2. 补充数据源：Google Books API                                  │
│     ├── 获取ISBN、封面、简介                                       │
│     ├── 数据标准化                                                │
│     └── 免费且稳定                                                │
│                                                                 │
│  3. 备用数据源：Open Library API                                  │
│     ├── 补充缺失数据                                              │
│     ├── 开放数据                                                  │
│     └── 社区维护                                                  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 6.2 数据流程

```
出版社网站爬虫 ──┬──> 原始数据（书名、作者、出版日期）
                │
                ▼
         数据清洗与标准化
                │
                ▼
         ISBN提取与验证
                │
                ▼
    Google Books API ──> 补充数据（封面、简介、分类）
                │
                ▼
            数据入库
```

---

## 七、总结

### 7.1 关键发现

1. **五大出版社均无公开API** - 需要通过网页爬虫获取新书数据
2. **Google Books API 是最佳补充数据源** - 免费、稳定、覆盖广
3. **出版社网站结构各异** - 需要针对每个网站编写专门的爬虫
4. **数据获取需要合规** - 遵守robots.txt，设置合理延迟

### 7.2 下一步建议

| 优先级 | 建议 |
|:------:|------|
| 高 | 完善现有5家出版社爬虫的选择器 |
| 高 | 添加爬虫监控和告警机制 |
| 中 | 使用Google Books API补充图书详情 |
| 中 | 添加更多出版社爬虫 |
| 低 | 考虑购买专业图书数据服务 |

---

**文档版本**: v1.0  
**最后更新**: 2026-02-26  
**维护者**: BookRank Team

"""
èŽ·å¥–å›¾ä¹¦ç®¡ç†æœåŠ¡

æä¾›èŽ·å¥–å›¾ä¹¦çš„è‡ªåŠ¨åˆ·æ–°ã€å¢žé‡æ›´æ–°ã€æ•°æ®æ¸…ç†ç­‰åŠŸèƒ½
æ”¯æŒä»Ž Wikidata å’Œ Open Library API èŽ·å–æœ€æ–°æ•°æ®
"""

import logging
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any

import json
from ..models import db
from ..models.schemas import Award, AwardBook, SystemConfig
from .api_client import WikidataClient, OpenLibraryClient, ImageCacheService, GoogleBooksClient

logger = logging.getLogger(__name__)


class AwardBookService:
    """
    èŽ·å¥–å›¾ä¹¦ç®¡ç†æœåŠ¡
    
    åŠŸèƒ½ï¼š
    - æ™ºèƒ½åˆ·æ–°ï¼šæ ¹æ®ä¸Šæ¬¡åˆ·æ–°æ—¶é—´å†³å®šæ˜¯å¦åˆ·æ–°
    - å¢žé‡æ›´æ–°ï¼šåªæ›´æ–°æ–°å¢žæˆ–å˜æ›´çš„å›¾ä¹¦
    - å°é¢èŽ·å–ï¼šè‡ªåŠ¨ä»Ž API èŽ·å–å°é¢å›¾ç‰‡
    - æ•°æ®æ¸…ç†ï¼šæ¸…ç†è¿‡æœŸæˆ–æ— æ•ˆæ•°æ®
    """
    
    # å¥–é¡¹åç§°æ˜ å°„ (Wikidata key -> æ•°æ®åº“åç§°)
    AWARD_NAME_MAP = {
        'nebula': 'æ˜Ÿäº‘å¥–',
        'hugo': 'é›¨æžœå¥–',
        'booker': 'å¸ƒå…‹å¥–',
        'international_booker': 'å›½é™…å¸ƒå…‹å¥–',
        'pulitzer_fiction': 'æ™®åˆ©ç­–å¥–',
        'edgar': 'çˆ±ä¼¦Â·å¡å¥–',
        'nobel_literature': 'è¯ºè´å°”æ–‡å­¦å¥–',
    }
    
    # å¥–é¡¹ç±»åˆ«æ˜ å°„
    AWARD_CATEGORY_MAP = {
        'nebula': 'æœ€ä½³é•¿ç¯‡å°è¯´',
        'hugo': 'æœ€ä½³é•¿ç¯‡å°è¯´',
        'booker': 'å°è¯´',
        'international_booker': 'ç¿»è¯‘å°è¯´',
        'pulitzer_fiction': 'å°è¯´',
        'edgar': 'æœ€ä½³å°è¯´',
        'nobel_literature': 'æ–‡å­¦',
    }
    
    def __init__(self, app=None):
        self.app = app
        self.wikidata_client = WikidataClient(timeout=30)
        self.openlib_client = OpenLibraryClient(timeout=10)
        self.google_books_client = GoogleBooksClient(timeout=10)
        
        if app:
            self.image_cache = ImageCacheService(
                cache_dir=app.config['IMAGE_CACHE_DIR'],
                default_cover='/static/default-cover.png'
            )
        else:
            self.image_cache = None
    
    def should_refresh(self, force: bool = False, refresh_interval_days: int = 7) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ•°æ®
        
        Args:
            force: å¼ºåˆ¶åˆ·æ–°
            refresh_interval_days: åˆ·æ–°é—´éš”å¤©æ•°
            
        Returns:
            æ˜¯å¦éœ€è¦åˆ·æ–°
        """
        if force:
            return True
        
        # èŽ·å–ä¸Šæ¬¡åˆ·æ–°æ—¶é—´
        last_refresh = SystemConfig.get_value('award_books_last_refresh')
        
        if not last_refresh:
            logger.info("ðŸ”„ é¦–æ¬¡è¿è¡Œï¼Œéœ€è¦åˆ·æ–°æ•°æ®")
            return True
        
        try:
            last_refresh_time = datetime.fromisoformat(last_refresh)
            next_refresh_time = last_refresh_time + timedelta(days=refresh_interval_days)
            
            if datetime.now() >= next_refresh_time:
                logger.info(f"ðŸ”„ è·ç¦»ä¸Šæ¬¡åˆ·æ–°å·²è¶…è¿‡ {refresh_interval_days} å¤©ï¼Œéœ€è¦åˆ·æ–°")
                return True
            else:
                days_left = (next_refresh_time - datetime.now()).days
                logger.info(f"â­ï¸ è·ç¦»ä¸‹æ¬¡åˆ·æ–°è¿˜æœ‰ {days_left} å¤©")
                return False
                
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æžä¸Šæ¬¡åˆ·æ–°æ—¶é—´å¤±è´¥: {e}")
            return True
    
    def update_refresh_time(self):
        """æ›´æ–°ä¸Šæ¬¡åˆ·æ–°æ—¶é—´"""
        SystemConfig.set_value('award_books_last_refresh', datetime.now().isoformat())
        db.session.commit()
        logger.info("âœ… å·²æ›´æ–°åˆ·æ–°æ—¶é—´")
    
    def refresh_award_books(self, award_keys: List[str] = None, 
                           start_year: int = 2020, 
                           end_year: int = 2025,
                           force: bool = False) -> Dict[str, Any]:
        """
        åˆ·æ–°èŽ·å¥–å›¾ä¹¦æ•°æ®
        
        Args:
            award_keys: è¦åˆ·æ–°çš„å¥–é¡¹åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰
            start_year: å¼€å§‹å¹´ä»½
            end_year: ç»“æŸå¹´ä»½
            force: å¼ºåˆ¶åˆ·æ–°
            
        Returns:
            åˆ·æ–°ç»“æžœç»Ÿè®¡
        """
        if not self.should_refresh(force):
            return {'status': 'skipped', 'message': 'æœªè¾¾åˆ°åˆ·æ–°æ—¶é—´'}
        
        if award_keys is None:
            award_keys = list(self.AWARD_NAME_MAP.keys())
        
        logger.info(f"ðŸš€ å¼€å§‹åˆ·æ–° {len(award_keys)} ä¸ªå¥–é¡¹çš„å›¾ä¹¦æ•°æ® ({start_year}-{end_year})...")
        
        stats = {
            'total_awards': len(award_keys),
            'processed_awards': 0,
            'new_books': 0,
            'updated_books': 0,
            'failed_books': 0,
            'errors': []
        }
        
        try:
            # ä»Ž Wikidata èŽ·å–æ•°æ®
            award_books_data = self.wikidata_client.get_all_award_books(
                awards=award_keys,
                start_year=start_year,
                end_year=end_year
            )
            
            # å¤„ç†æ¯ä¸ªå¥–é¡¹
            for award_key, books_data in award_books_data.items():
                try:
                    result = self._process_award_books(award_key, books_data)
                    stats['new_books'] += result['new']
                    stats['updated_books'] += result['updated']
                    stats['failed_books'] += result['failed']
                    stats['processed_awards'] += 1
                except Exception as e:
                    error_msg = f"å¤„ç† {award_key} å¤±è´¥: {e}"
                    logger.error(error_msg)
                    stats['errors'].append(error_msg)
            
            # æ›´æ–°åˆ·æ–°æ—¶é—´
            self.update_refresh_time()
            
            logger.info(f"âœ… åˆ·æ–°å®Œæˆ: æ–°å¢ž {stats['new_books']} æœ¬, æ›´æ–° {stats['updated_books']} æœ¬")
            
        except Exception as e:
            error_msg = f"åˆ·æ–°è¿‡ç¨‹å‡ºé”™: {e}"
            logger.error(error_msg)
            stats['errors'].append(error_msg)
        
        return stats
    
    def _process_award_books(self, award_key: str, books_data: List[Dict]) -> Dict[str, int]:
        """
        å¤„ç†å•ä¸ªå¥–é¡¹çš„å›¾ä¹¦æ•°æ®
        
        Args:
            award_key: å¥–é¡¹é”®å
            books_data: å›¾ä¹¦æ•°æ®åˆ—è¡¨
            
        Returns:
            å¤„ç†ç»“æžœç»Ÿè®¡
        """
        result = {'new': 0, 'updated': 0, 'failed': 0}
        
        award_name = self.AWARD_NAME_MAP.get(award_key, award_key)
        category = self.AWARD_CATEGORY_MAP.get(award_key, 'å…¶ä»–')
        
        # èŽ·å–æˆ–åˆ›å»ºå¥–é¡¹
        award = Award.query.filter_by(name=award_name).first()
        if not award:
            award = Award(
                name=award_name,
                description=f'{award_name}èŽ·å¥–å›¾ä¹¦',
                country='å›½é™…' if 'å›½é™…' in award_name else 'ç¾Žå›½',
                category=category
            )
            db.session.add(award)
            db.session.flush()
            logger.info(f"âœ… åˆ›å»ºå¥–é¡¹: {award_name}")
        
        # å¤„ç†æ¯æœ¬å›¾ä¹¦
        for book_data in books_data:
            try:
                process_result = self._process_single_book(award, book_data, category)
                result[process_result] += 1
            except Exception as e:
                logger.error(f"å¤„ç†å›¾ä¹¦å¤±è´¥ {book_data.get('title')}: {e}")
                result['failed'] += 1
            
            # å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.3)
        
        db.session.commit()
        return result
    
    def _process_single_book(self, award: Award, book_data: Dict, category: str) -> str:
        """
        å¤„ç†å•æœ¬å›¾ä¹¦
        
        Args:
            award: å¥–é¡¹å¯¹è±¡
            book_data: å›¾ä¹¦æ•°æ®
            category: ç±»åˆ«
            
        Returns:
            å¤„ç†ç»“æžœ: 'new', 'updated', 'skipped'
        """
        isbn = book_data.get('isbn13') or book_data.get('isbn10')
        if not isbn:
            logger.warning(f"âš ï¸ å›¾ä¹¦æ—  ISBN: {book_data.get('title')}")
            return 'failed'
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = AwardBook.query.filter_by(
            award_id=award.id,
            isbn13=isbn if len(isbn) == 13 else None
        ).first()
        
        if existing:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            needs_update = False
            
            if not existing.cover_local_path and self.image_cache:
                # å°è¯•èŽ·å–å°é¢
                cover_url = self._get_cover_url(isbn)
                if cover_url:
                    cached_path = self.image_cache.get_cached_image_url(cover_url)
                    if cached_path and cached_path != '/static/default-cover.png':
                        existing.cover_original_url = cover_url
                        existing.cover_local_path = cached_path
                        needs_update = True
            
            if needs_update:
                db.session.commit()
                logger.info(f"ðŸ”„ æ›´æ–°å›¾ä¹¦: {existing.title[:40]}...")
                return 'updated'
            
            return 'skipped'
        
        # èŽ·å–å›¾ä¹¦è¯¦æƒ… (Open Library)
        book_details = self.openlib_client.fetch_book_by_isbn(isbn)
        
        # èŽ·å– Google Books æ•°æ®ï¼ˆè¯¦ç»†ä¿¡æ¯å’Œè´­ä¹°é“¾æŽ¥ï¼‰
        google_books_data = self.google_books_client.search_by_isbn(isbn)
        
        # èŽ·å–å°é¢ï¼ˆä¼˜å…ˆ Open Libraryï¼ŒåŽè¡¥ Google Booksï¼‰
        cover_url = self._get_cover_url(isbn)
        
        # å¦‚æžœ Open Library æ²¡æœ‰å°é¢ï¼Œå°è¯• Google Books
        if not cover_url and google_books_data.get('cover_url'):
            cover_url = google_books_data['cover_url']
            logger.info(f"ðŸ“š ä»Ž Google Books èŽ·å–å°é¢: {book_data['title'][:40]}...")
        
        cover_local_path = None
        if cover_url and self.image_cache:
            cover_local_path = self.image_cache.get_cached_image_url(cover_url)
            if cover_local_path == '/static/default-cover.png':
                cover_local_path = None
        
        # æå–æè¿°ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨æ›´è¯¦ç»†çš„æ¥æºï¼‰
        def get_description(preferred_source, fallback_source, default_msg):
            """èŽ·å–æè¿°ï¼Œä¼˜å…ˆä½¿ç”¨æŒ‡å®šæ¥æº"""
            desc = preferred_source.get('description')
            if desc and len(desc) > 50:
                return desc
            desc = fallback_source.get('description')
            if desc and len(desc) > 50:
                return desc
            return default_msg
        
        description = get_description(book_details, google_books_data, f'{award.name}èŽ·å¥–ä½œå“')
        details = get_description(google_books_data, book_details, '')
        
        # èŽ·å–è´­ä¹°é“¾æŽ¥
        buy_links = google_books_data.get('buy_links', {})
        
        # åˆ›å»ºæ–°å›¾ä¹¦è®°å½•
        book = AwardBook(
            award_id=award.id,
            year=book_data['year'],
            category=category,
            rank=1,
            title=book_data['title'],
            author=book_data.get('author') or book_details.get('author') or google_books_data.get('author') or 'Unknown',
            description=description,
            details=details,
            isbn13=isbn if len(isbn) == 13 else None,
            isbn10=isbn if len(isbn) == 10 else None,
            cover_original_url=cover_url,
            cover_local_path=cover_local_path,
            buy_links=json.dumps(buy_links) if buy_links else None
        )
        
        db.session.add(book)
        logger.info(f"âœ… æ–°å¢žå›¾ä¹¦: {book.title[:40]}...")
        return 'new'
    
    def _get_cover_url(self, isbn: str) -> Optional[str]:
        """èŽ·å–å°é¢ URLï¼ˆä¼˜å…ˆ Open Libraryï¼ŒåŽè¡¥ Google Booksï¼‰"""
        # å°è¯• Open Library
        cover_url = self.openlib_client.get_cover_url(isbn, size='L')
        if cover_url:
            return cover_url
        
        # TODO: å¦‚æžœéœ€è¦ï¼Œå¯ä»¥æ·»åŠ  Google Books ä½œä¸ºå¤‡ç”¨
        return None
    
    def fetch_missing_covers(self, batch_size: int = 10) -> Dict[str, int]:
        """
        ä¸ºç¼ºå¤±å°é¢çš„å›¾ä¹¦èŽ·å–å°é¢
        
        Args:
            batch_size: æ¯æ‰¹å¤„ç†æ•°é‡
            
        Returns:
            å¤„ç†ç»“æžœç»Ÿè®¡
        """
        if not self.image_cache:
            logger.error("âŒ ImageCacheService æœªåˆå§‹åŒ–")
            return {'success': 0, 'failed': 0}
        
        # èŽ·å–ç¼ºå¤±å°é¢çš„å›¾ä¹¦
        books = AwardBook.query.filter(
            (AwardBook.cover_local_path.is_(None)) | 
            (AwardBook.cover_local_path == '/static/default-cover.png')
        ).limit(batch_size).all()
        
        if not books:
            logger.info("âœ… æ‰€æœ‰å›¾ä¹¦å·²æœ‰å°é¢")
            return {'success': 0, 'failed': 0}
        
        logger.info(f"ðŸ“š å¼€å§‹ä¸º {len(books)} æœ¬å›¾ä¹¦èŽ·å–å°é¢...")
        
        stats = {'success': 0, 'failed': 0}
        
        for book in books:
            try:
                isbn = book.isbn13 or book.isbn10
                if not isbn:
                    continue
                
                cover_url = self._get_cover_url(isbn)
                if not cover_url:
                    stats['failed'] += 1
                    continue
                
                cached_path = self.image_cache.get_cached_image_url(cover_url)
                if cached_path and cached_path != '/static/default-cover.png':
                    book.cover_original_url = cover_url
                    book.cover_local_path = cached_path
                    stats['success'] += 1
                    logger.info(f"âœ… {book.title[:40]}...")
                else:
                    stats['failed'] += 1
                
                time.sleep(0.3)
                
            except Exception as e:
                logger.error(f"âŒ èŽ·å–å°é¢å¤±è´¥: {e}")
                stats['failed'] += 1
        
        db.session.commit()
        logger.info(f"âœ… å°é¢èŽ·å–å®Œæˆ: æˆåŠŸ {stats['success']} æœ¬, å¤±è´¥ {stats['failed']} æœ¬")
        
        return stats
    
    def get_refresh_status(self) -> Dict[str, Any]:
        """èŽ·å–åˆ·æ–°çŠ¶æ€"""
        last_refresh = SystemConfig.get_value('award_books_last_refresh')
        
        if not last_refresh:
            return {
                'last_refresh': None,
                'next_refresh': None,
                'days_since_last': None,
                'needs_refresh': True
            }
        
        try:
            last_time = datetime.fromisoformat(last_refresh)
            next_time = last_time + timedelta(days=7)
            days_since = (datetime.now() - last_time).days
            
            return {
                'last_refresh': last_refresh,
                'next_refresh': next_time.isoformat(),
                'days_since_last': days_since,
                'needs_refresh': days_since >= 7
            }
        except:
            return {
                'last_refresh': last_refresh,
                'next_refresh': None,
                'days_since_last': None,
                'needs_refresh': True
            }
